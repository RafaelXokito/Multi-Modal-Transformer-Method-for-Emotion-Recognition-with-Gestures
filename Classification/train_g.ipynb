{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torchsummary import summary\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'anger', 1: 'contempt', 2: 'disgust', 3: 'fear', 4: 'happy', 5: 'neutral', 6: 'sad', 7: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "bs = 32\n",
    "# Number of epochs to train for \n",
    "num_epochs = 30\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "# Applying Transforms to the Data\n",
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((228, 228)),\n",
    "        transforms.RandomCrop(size=224),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.AutoAugment(transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4569],\n",
    "                             [0.2344])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize((228, 228)),\n",
    "        transforms.RandomCrop(size=224),\n",
    "        transforms.Grayscale(), \n",
    "        transforms.AutoAugment(transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4569],\n",
    "                             [0.2344])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        # transforms.RandomCrop(size=224),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4569],\n",
    "                             [0.2344])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the Data\n",
    "# Set train and valid directory paths\n",
    "\n",
    "dataset_directory = r\"../datasets/AffectNet_10Percent_SegmentedFaces_G\"\n",
    "\n",
    "train_directory = os.path.join(dataset_directory, 'train')\n",
    "valid_directory = os.path.join(dataset_directory, 'valid')\n",
    "test_directory = os.path.join(dataset_directory, 'test')\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))\n",
    "    \n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid']),\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "test_data_size = len(data['test'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=True)\n",
    "test_data_loader = DataLoader(data['test'], batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_validate(model, criterion, optimizer, epochs=25):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_loss = 100000.0\n",
    "    best_epoch = None\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "            inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss - by loss function \"criterion\"\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients - altera os pesos\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters - aplicação de alterações\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions)) # - contar quantos acertou\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "        \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(valid_data_loader):\n",
    "                inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "        \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        log = \"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start)\n",
    "        print(log)\n",
    "        with open(os.path.join(history_path, 'train.log'), 'a') as the_file:\n",
    "            the_file.write(log + '\\n')\n",
    "\n",
    "        # Save if the model has best accuracy till now\n",
    "        if epoch == num_epochs -1 :\n",
    "            torch.save(model, os.path.join(history_path, 'last_model.pt'))\n",
    "            model.load_state_dict(best_model)\n",
    "            torch.save(model, os.path.join(history_path, f'best_model_epoch{best_epoch+1}.pt'))\n",
    "            \n",
    "    return model, history, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        set_parameter_requires_grad(model_ft)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        #model_ft = torch.load(\"model_999_t3.pt\")\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)       \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=True)\n",
    "\n",
    "        # Modify the first convolutional layer to accept 1 input channel\n",
    "        old_weights = model_ft.features[0].weight\n",
    "        new_weights = old_weights[:, 0:1, :, :]\n",
    "        new_conv = torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight = torch.nn.Parameter(new_weights)\n",
    "\n",
    "        # Replace the first convolutional layer in the VGG11 model with the new layer\n",
    "        model_ft.features[0] = new_conv\n",
    "\n",
    "        set_parameter_requires_gradTrue_nofc(model_ft)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        print(num_classes)\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(weights=None)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(weights=None)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Freeze\n",
    "def set_parameter_requires_grad(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "            \n",
    "#UnFreeze\n",
    "def set_parameter_requires_gradTrue(model):\n",
    "    num=0\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "        # if num >= 30 :\n",
    "        #     param.requires_grad = True\n",
    "        # num=num+1\n",
    "\n",
    "def set_parameter_requires_gradTrue_nofc(model):\n",
    "    num=0\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch: 1/30\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 1, 224, 224] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     43\u001b[0m \u001b[39m# Train and evaluate\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m best_model, history, best_epoch \u001b[39m=\u001b[39m train_and_validate(model_ft, criterion, optimizer_ft, epochs\u001b[39m=\u001b[39;49mnum_epochs)\n\u001b[1;32m     46\u001b[0m history \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(history)\n\u001b[1;32m     47\u001b[0m plt\u001b[39m.\u001b[39mplot(history[:,\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m])\n",
      "Cell \u001b[0;32mIn[83], line 43\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     42\u001b[0m \u001b[39m# Forward pass - compute outputs on input data using the model\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Compute loss - by loss function \"criterion\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/miniforge3/envs/MMTMERG/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/MMTMERG/lib/python3.8/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/MMTMERG/lib/python3.8/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/MMTMERG/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/MMTMERG/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/envs/MMTMERG/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 1, 224, 224] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract)\n",
    "\n",
    "if model_name != 'vgg':\n",
    "    set_parameter_requires_gradTrue(model_ft)\n",
    "        \n",
    "# Device used to train the network (Ex: GPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Send the model to the processing unit\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\", name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "curr_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "history_path = os.path.join('./history/', curr_time)\n",
    "\n",
    "os.mkdir(history_path)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "best_model, history, best_epoch = train_and_validate(model_ft, criterion, optimizer_ft, epochs=num_epochs)\n",
    "\n",
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,3)\n",
    "plt.savefig(os.path.join(history_path, 'loss_curve.png'))\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(os.path.join(history_path, 'accuracy_curve.png'))\n",
    "plt.show()\n",
    "\n",
    "def computeTestSetAccuracy(loss_criterion):\n",
    "    '''\n",
    "    Function to compute the accuracy on the test set\n",
    "    Parameters\n",
    "        :param model: Model to test\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "    '''\n",
    "    # model = torch.load(os.path.join(history_path, \"model.pt\"))\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # Validation - No gradient tracking needed\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model = best_model\n",
    "        \n",
    "        # Set to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Validation loop\n",
    "        for j, (inputs, labels) in enumerate(test_data_loader):\n",
    "            inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # labels.cpu().numpy()\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            # Compute the total loss for the batch and add it to valid_loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # Confusion matrix\n",
    "            for t, p in zip(labels.view(-1), predictions.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "            # Compute total accuracy in the whole batch and add to valid_acc\n",
    "            test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            log = \"Test Batch number: {:03d}, Test: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item())\n",
    "            print(log)\n",
    "            \n",
    "            with open(os.path.join(history_path, 'test.log'), 'a') as the_file:\n",
    "                the_file.write(log + '\\n')\n",
    "\n",
    "    # Find average test loss and test accuracy\n",
    "    avg_test_loss = test_loss/test_data_size \n",
    "    avg_test_acc = test_acc/test_data_size\n",
    "\n",
    "    cm = confusion_matrix.cpu().numpy()\n",
    "    plt.imshow(cm, cmap='gray_r')\n",
    "    plt.colorbar()\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:.0f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > (cm.max() / 1.5) else \"black\")\n",
    "\n",
    "    tick_marks = np.arange(len(confusion_matrix))\n",
    "    plt.xticks(tick_marks, idx_to_class.values(), rotation=45)\n",
    "    plt.yticks(tick_marks, idx_to_class.values())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(os.path.join(history_path, 'confusion_matrix.png'), bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    indiv_acc = (confusion_matrix.diag()/confusion_matrix.sum(1)).numpy()\n",
    "\n",
    "    print(\"Test Accuracy : \" + str(avg_test_acc))\n",
    "\n",
    "    print(\"Test Accuracy Per Class :\")\n",
    "\n",
    "    for key in idx_to_class:\n",
    "        print(f\"{idx_to_class[key]} - {round(indiv_acc[key] * 100, 4)}%\")\n",
    "\n",
    "    with open(os.path.join(history_path, 'test.log'), 'a') as the_file:\n",
    "        the_file.write(\"Test Accuracy : \" + str(avg_test_acc) + \"\\n\\n\")\n",
    "        the_file.write(\"Test Accuracy Per Class : \\n\")\n",
    "        for key in idx_to_class:\n",
    "            the_file.write(f\"{idx_to_class[key]} - {round(indiv_acc[key] * 100, 4)}%\\n\")\n",
    "\n",
    "computeTestSetAccuracy(criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMTMERG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d3c456ffaa9cd28f83f00357dff394a6c471d38d2284dc7337cbaff2c725068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
